{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13d9b7-45dd-43f5-8e80-f7e7ce547ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a90ab6-ff35-44e5-8f37-27ef6b2c5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_form(boxes):\n",
    "    \"\"\" Convert prior_boxes to (xmin, ymin, xmax, ymax)\n",
    "    representation for comparison to point form ground truth data.\n",
    "    Args:\n",
    "        boxes: (tensor) center-size default boxes from priorbox layers.\n",
    "    Return:\n",
    "        boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.\n",
    "    \"\"\"\n",
    "    return torch.cat((boxes[:, :2] - boxes[:, 2:]/2,     # xmin, ymin\n",
    "                     boxes[:, :2] + boxes[:, 2:]/2), 1)  # xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8a14d-7cbd-47a6-94a7-6375046b303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):\n",
    "    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n",
    "    [A,2] -> [A,1,2] -> [A,B,2]\n",
    "    [B,2] -> [1,B,2] -> [A,B,2]\n",
    "    Then we compute the area of intersect between box_a and box_b.\n",
    "    Args:\n",
    "      box_a: (tensor) bounding boxes, Shape: [A,4].\n",
    "      box_b: (tensor) bounding boxes, Shape: [B,4].\n",
    "    Return:\n",
    "      (tensor) intersection area, Shape: [A,B].\n",
    "    \"\"\"\n",
    "    A = box_a.size(0)\n",
    "    B = box_b.size(0)\n",
    "    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n",
    "                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n",
    "    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n",
    "                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30755fc2-6b5f-4c7d-9dd7-86d753f5d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(box_a, box_b):\n",
    "    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n",
    "    is simply the intersection over union of two boxes.  Here we operate on\n",
    "    ground truth boxes and default boxes.\n",
    "    E.g.:\n",
    "        A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)\n",
    "    Args:\n",
    "        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n",
    "        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n",
    "    Return:\n",
    "        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n",
    "    \"\"\"\n",
    "    inter = intersect(box_a, box_b)\n",
    "    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n",
    "              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n",
    "    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n",
    "              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union  # [A,B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c9bed-9226-412b-9026-1cdda0c366d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(matched, priors, variances):\n",
    "    \"\"\"Encode the variances from the priorbox layers into the ground truth boxes\n",
    "    we have matched (based on jaccard overlap) with the prior boxes.\n",
    "    Args:\n",
    "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
    "            Shape: [num_priors, 4].\n",
    "        priors: (tensor) Prior boxes in center-offset form\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        encoded boxes (tensor), Shape: [num_priors, 4]\n",
    "    \"\"\"\n",
    "\n",
    "    # dist b/t match center and prior's center\n",
    "    g_cxcy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2]\n",
    "    # encode variance\n",
    "    g_cxcy /= (variances[0] * priors[:, 2:])\n",
    "    # match wh / prior wh\n",
    "    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]\n",
    "    g_wh = torch.log(g_wh) / variances[1]\n",
    "    # return target for smooth_l1_loss\n",
    "    return torch.cat([g_cxcy, g_wh], 1)  # [num_priors,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b842ca-5b06-44aa-b5ad-f5cab5f09546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx):\n",
    "    \"\"\"Match each prior box with the ground truth box of the highest jaccard\n",
    "    overlap, encode the bounding boxes, then return the matched indices\n",
    "    corresponding to both confidence and location preds.\n",
    "    Args:\n",
    "        threshold: (float) The overlap threshold used when mathing boxes.\n",
    "        truths: (tensor) Ground truth boxes, Shape: [num_obj, num_priors].\n",
    "        priors: (tensor) Prior boxes from priorbox layers, Shape: [n_priors,4].\n",
    "        variances: (tensor) Variances corresponding to each prior coord,\n",
    "            Shape: [num_priors, 4].\n",
    "        labels: (tensor) All the class labels for the image, Shape: [num_obj].\n",
    "        loc_t: (tensor) Tensor to be filled w/ endcoded location targets.\n",
    "        conf_t: (tensor) Tensor to be filled w/ matched indices for conf preds.\n",
    "        idx: (int) current batch index\n",
    "    Return:\n",
    "        The matched indices corresponding to 1)location and 2)confidence preds.\n",
    "    \"\"\"\n",
    "    # jaccard index\n",
    "    overlaps = jaccard(\n",
    "        truths,\n",
    "        point_form(priors)\n",
    "    )\n",
    "    # (Bipartite Matching)\n",
    "    # [1,num_objects] best prior for each ground truth\n",
    "    best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True)\n",
    "    # [1,num_priors] best ground truth for each prior\n",
    "    best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True)\n",
    "    best_truth_idx.squeeze_(0)\n",
    "    best_truth_overlap.squeeze_(0)\n",
    "    best_prior_idx.squeeze_(1)\n",
    "    best_prior_overlap.squeeze_(1)\n",
    "    best_truth_overlap.index_fill_(0, best_prior_idx, 2)  # ensure best prior\n",
    "    # TODO refactor: index  best_prior_idx with long tensor\n",
    "    # ensure every gt matches with its prior of max overlap\n",
    "    for j in range(best_prior_idx.size(0)):\n",
    "        best_truth_idx[best_prior_idx[j]] = j\n",
    "    matches = truths[best_truth_idx]          # Shape: [num_priors,4]\n",
    "    conf = labels[best_truth_idx] + 1         # Shape: [num_priors]\n",
    "    conf[best_truth_overlap < threshold] = 0  # label as background\n",
    "    loc = encode(matches, priors, variances)\n",
    "    loc_t[idx] = loc    # [num_priors,4] encoded offsets to learn\n",
    "    conf_t[idx] = conf  # [num_priors] top class label for each prior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
